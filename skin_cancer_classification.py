# -*- coding: utf-8 -*-
"""skin_cancer_classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WMEW6igsmGIN1SU_B_SJC4f8gmPkZER1
"""

# %%capture
!pip install patool

import patoolib

patoolib.extract_archive('/content/drive/MyDrive/skin_cancer_dataset.zip')

import numpy as np
import pandas as pd
import seaborn as sb
import matplotlib.pyplot as plt
import os
from glob import glob
from PIL import Image
from sklearn.model_selection import train_test_split

import tensorflow as tf
from tensorflow import keras
from keras import layers
from functools import partial

AUTO = tf.data.experimental.AUTOTUNE
import warnings
warnings.filterwarnings('ignore')

train = glob('/content/skin_cancer_dataset/train/*/*.jpg')
print('Train:', len(train))
test = glob('/content/skin_cancer_dataset/test/*/*.jpg')
print('Test', len(test))

train_dir = '/content/skin_cancer_dataset/train'
test_dir = '/content/skin_cancer_dataset/test'

# More efficient approach
def create_dataframe_from_directory(base_dir):
    data = []
    for label, directory in enumerate(os.listdir(base_dir)):
        if directory == '.ipynb_checkpoints':
            continue

        dir_path = os.path.join(base_dir, directory)
        if os.path.isdir(dir_path):
            for filename in os.listdir(dir_path):
                if filename.endswith(('.png', '.jpg', '.jpeg')):
                    image_path = os.path.join(dir_path, filename)
                    data.append([image_path, label])

    return pd.DataFrame(data, columns=['image_path', 'label'])

# Create dataframes
train_df = create_dataframe_from_directory(train_dir)
test_df = create_dataframe_from_directory(test_dir)

# Combine
df = pd.concat([train_df, test_df], ignore_index=True)

df.head()

df['label'].value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=90)
plt.axis('equal')
plt.title('Distribution of Labels in DataFrame')
legend_labels = ['0 - benign', '1 - malignant']
plt.legend(legend_labels)
plt.show()

for cat in df['label'].unique():
    temp = df[df['label'] == cat]

    index_list = temp.index
    fig, ax = plt.subplots(1, 4, figsize=(15, 5))
    fig.suptitle(f'Images for {cat} category . . . .', fontsize=20)
    for i in range(4):
        index = np.random.randint(0, len(index_list))
        index = index_list[index]
        data = df.iloc[index]

        image_path = data[0]

        img = np.array(Image.open(image_path))
        ax[i].imshow(img)
plt.tight_layout()
plt.show()

# First, create dataframes from your directories (as we did earlier)
def create_dataframe_from_directory(base_dir):
    data = []
    for label, directory in enumerate(os.listdir(base_dir)):
        if directory == '.ipynb_checkpoints':
            continue

        dir_path = os.path.join(base_dir, directory)
        if os.path.isdir(dir_path):
            for filename in os.listdir(dir_path):
                if filename.endswith(('.png', '.jpg', '.jpeg', '.JPG', '.PNG')):
                    image_path = os.path.join(dir_path, filename)
                    data.append([image_path, label])

    return pd.DataFrame(data, columns=['image_path', 'label'])

# Create dataframes
train_df = create_dataframe_from_directory(train_dir)
test_df = create_dataframe_from_directory(test_dir)

# Split training data into train and validation (e.g., 80% train, 20% validation)
train_df, val_df = train_test_split(
    train_df,
    test_size=0.2,
    random_state=42,
    stratify=train_df['label']
)

print(f"Train: {len(train_df)}")
print(f"Validation: {len(val_df)}")
print(f"Test: {len(test_df)}")

def create_dataset(df, batch_size=32, img_size=(224, 224), shuffle=True):
    def load_and_preprocess(image_path, label):
        # Read and decode image
        image = tf.io.read_file(image_path)
        image = tf.image.decode_jpeg(image, channels=3)  # or decode_png
        image = tf.image.resize(image, img_size)
        image = tf.cast(image, tf.float32) / 255.0
        return image, label

    # Create dataset
    paths = df['image_path'].values
    labels = df['label'].values

    dataset = tf.data.Dataset.from_tensor_slices((paths, labels))

    if shuffle:
        dataset = dataset.shuffle(buffer_size=len(df))

    dataset = dataset.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)
    dataset = dataset.batch(batch_size)
    dataset = dataset.prefetch(tf.data.AUTOTUNE)

    return dataset

# Create datasets
batch_size = 32
train_ds = create_dataset(train_df, batch_size, shuffle=True)
val_ds = create_dataset(val_df, batch_size, shuffle=False)  # No shuffle for validation
test_ds = create_dataset(test_df, batch_size, shuffle=False)  # No shuffle for test

from tensorflow.keras.applications.efficientnet import EfficientNetB7

pre_trained_model = EfficientNetB7(
    input_shape=(224, 224, 3),
    weights='imagenet',
    include_top=False
)

for layer in pre_trained_model.layers:
    layer.trainable = False

from tensorflow.keras import Model

inputs = layers.Input(shape=(224, 224, 3))
x = layers.Flatten()(inputs)

x = layers.Dense(256, activation='relu')(x)
x = layers.BatchNormalization()(x)
x = layers.Dense(256, activation='relu')(x)
x = layers.Dropout(0.3)(x)
x = layers.BatchNormalization()(x)
outputs = layers.Dense(1, activation='sigmoid')(x)

model = Model(inputs, outputs)

model.summary()

model.compile(
    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
    optimizer='adam',
    metrics=['accuracy']
)

from keras.callbacks import EarlyStopping, ModelCheckpoint
epochs = 20
callbacks = [
    EarlyStopping(
        monitor='val_loss',
        patience=5,
        restore_best_weights=True)
]

checkpointer = ModelCheckpoint(filepath='cc_best_model.keras',
                                monitor='val_loss',
                                save_best_only=True,
                                verbose=1)

history = model.fit(x=train_ds,
                    validation_data=val_ds,
                    epochs=epochs,
                    verbose=1,
                    callbacks=[callbacks, checkpointer])

hist_df = pd.DataFrame(history.history)

# After training, evaluate on test set
test_loss, test_accuracy = model.evaluate(test_ds)
print(f"Test accuracy: {test_accuracy:.4f}")

hist_df['loss'].plot()
hist_df['val_loss'].plot()
plt.title('Loss v/s Validation Loss')
plt.legend()
plt.show()

hist_df['accuracy'].plot()
hist_df['val_accuracy'].plot()
plt.title('Accuracy vs Validation Accuracy')
plt.legend()
plt.show()